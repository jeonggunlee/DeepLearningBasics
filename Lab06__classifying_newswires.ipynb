{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05-classifying-newswires.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeonggunlee/OpenSourceKeras/blob/master/05_classifying_newswires.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-5ulYn5ZF0Xv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###한림대학교 소프트웨어 융합 대학 특강\n",
        "\n",
        "##누구나 즐기는 딥러닝: 오픈소스 Keras를 활용하여!!!\n",
        "\n",
        "이정근 교수\n",
        "\n",
        "빅데이터전공주임/오픈소스소프트웨어센터장 소프트웨어융합대학\n",
        "\n",
        "jeonggun.lee@hallym.ac.kr 2019년 5월\n",
        "\n",
        "\n",
        "---\n",
        "##로이터 뉴스 기사 분류: 다중 분류 문제\n",
        "\n",
        "로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류!\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "6uzJA2EPFywh",
        "colab_type": "code",
        "outputId": "9a467335-cd77-481f-a901-502419fec16a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "HOHgRzakInyE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 이하 자료는 모두 다음 사이트의 내용에서 가져온 자료입다.\n",
        "\n",
        "https://github.com/rickiepark/deep-learning-with-python-notebooks\n",
        "\n",
        "원작자: François Chollet, https://github.com/fchollet\n",
        "\n",
        "한글화: Haesun Park (rickiepark) https://github.com/rickiepark\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "JJQ-VpNTFywr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 뉴스 기사 분류: 다중 분류 문제\n",
        "\n",
        "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 3장 5절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다.\n",
        "\n",
        "----\n",
        "\n",
        "이전 섹션에서 완전 연결된 신경망을 사용해 벡터 입력을 어떻게 두 개의 클래스로 분류하는지 보았습니다. 두 개 이상의 클래스가 있을 때는 어떻게 해야 할까요?\n",
        "\n",
        "이 절에서 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어 보겠습니다. 클래스가 많기 때문에 이 문제는 다중 분류의 예입니다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제입니다. 각 데이터 포인트가 여러 개의 범주(가령, 토픽)에 속할 수 있다면 이런 문제는 다중 레이블 다중 분류의 문제가 됩니다."
      ]
    },
    {
      "metadata": {
        "id": "v0GGlk3-Fyws",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 로이터 데이터셋\n",
        "\n",
        "1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용하겠습니다. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋입니다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많습니다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다.\n",
        "\n",
        "IMDB와 MNIST와 마찬가지로 로이터 데이터셋은 케라스에 포함되어 있습니다. 한 번 살펴보죠:"
      ]
    },
    {
      "metadata": {
        "id": "nQgIccCvFywu",
        "colab_type": "code",
        "outputId": "ae771282-e251-4a45-9a31-2ae0fd439c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lm3C7q5tFywy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "IMDB 데이터셋에서처럼 num_words=10000 매개변수는 데이터에서 가장 자주 등장하는 단어 10,000개로 제한합니다.\n",
        "\n",
        "여기에는 8,982개의 훈련 샘플과 2,246개의 테스트 샘플이 있습니다:"
      ]
    },
    {
      "metadata": {
        "id": "EFsf6xHkFywz",
        "colab_type": "code",
        "outputId": "887c9cb5-e4dc-411e-8a8e-442ad81f77b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8982"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "aYoxaiKnFyw4",
        "colab_type": "code",
        "outputId": "3b945e61-251b-47ac-83e2-8ff5bd0d95f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2246"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "4qGswrGJFyw7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "IMDB 리뷰처럼 각 샘플은 정수 리스트입니다(단어 인덱스):"
      ]
    },
    {
      "metadata": {
        "id": "g6au2wkjFyw8",
        "colab_type": "code",
        "outputId": "abec45bc-9d54-4c41-8b27-4a946742f467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "cell_type": "code",
      "source": [
        "train_data[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 245,\n",
              " 273,\n",
              " 207,\n",
              " 156,\n",
              " 53,\n",
              " 74,\n",
              " 160,\n",
              " 26,\n",
              " 14,\n",
              " 46,\n",
              " 296,\n",
              " 26,\n",
              " 39,\n",
              " 74,\n",
              " 2979,\n",
              " 3554,\n",
              " 14,\n",
              " 46,\n",
              " 4689,\n",
              " 4329,\n",
              " 86,\n",
              " 61,\n",
              " 3499,\n",
              " 4795,\n",
              " 14,\n",
              " 61,\n",
              " 451,\n",
              " 4329,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "FWQWKYF3FyxB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "궁금한 경우를 위해 어떻게 단어로 디코딩하는지 알아보겠습니다:"
      ]
    },
    {
      "metadata": {
        "id": "3iDJpgkdFyxC",
        "colab_type": "code",
        "outputId": "e9d28d7d-e37c-4f20-dc46-0a09253d8500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ki-hYWADFyxF",
        "colab_type": "code",
        "outputId": "cf2cc127-d200-4656-8e73-d3aa1fd8eeb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "decoded_newswire"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "LIhp7cUJFyxJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수입니다."
      ]
    },
    {
      "metadata": {
        "id": "wuqHMRMeFyxK",
        "colab_type": "code",
        "outputId": "a0082c32-ba52-47e2-a32c-87ef93f5b96a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "x_cB6UmJFyxO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비\n",
        "\n",
        "이전의 예제와 동일한 코드를 사용해서 데이터를 벡터로 변환합니다:"
      ]
    },
    {
      "metadata": {
        "id": "wV1JXS8qFyxP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "# 훈련 데이터 벡터 변환\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 테스트 데이터 벡터 변환\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0lzOUhkcFyxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "레이블을 벡터로 바꾸는 방법은 두 가지입니다. 레이블의 리스트를 정수 텐서로 변환하는 것과 원-핫 인코딩을 사용하는 것입니다. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부릅니다. 원-핫 인코딩에 대한 자세한 설명은 6.1절을 참고하세요. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터입니다:"
      ]
    },
    {
      "metadata": {
        "id": "YokMwyN1FyxT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results\n",
        "\n",
        "# 훈련 레이블 벡터 변환\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "# 테스트 레이블 벡터 변환\n",
        "one_hot_test_labels = to_one_hot(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nFrT5WeIFyxW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "MNIST 예제에서 이미 보았듯이 케라스에는 이를 위한 내장 함수가 있습니다:"
      ]
    },
    {
      "metadata": {
        "id": "DEejkGZWFyxX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VMlKU4KgFyxb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 모델 구성\n",
        "\n",
        "이 토픽 분류 문제는 이전의 영화 리뷰 분류 문제와 비슷해 보입니다. 두 경우 모두 짧은 텍스트를 분류하는 것이죠. 여기에서는 새로운 제약 사항이 추가되었습니다. 출력 클래스의 개수가 2에서 46개로 늘어난 점입니다. 출력 공간의 차원이 훨씬 커졌습니다.\n",
        "\n",
        "이전에 사용했던 것처럼 `Dense` 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있습니다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없습니다. 각 층은 잠재적으로 정보의 병목이 될 수 있습니다. 이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많을 것 같습니다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있습니다.\n",
        "\n",
        "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다. 64개의 유닛을 사용해 보죠:"
      ]
    },
    {
      "metadata": {
        "id": "F_nuFoCVFyxc",
        "colab_type": "code",
        "outputId": "5e688edd-9b39-4cdc-edcf-af3223c9bce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J2xGSfGSFyxg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 구조에서 주목해야 할 점이 두 가지 있습니다:\n",
        "\n",
        "* 마지막 `Dense` 층의 크기가 46입니다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻입니다. 이 벡터의 각 원소(각 차원)은 각기 다른 출력 클래스가 인코딩된 것입니다.\n",
        "* 마지막 층에 `softmax` 활성화 함수가 사용되었습니다. MNIST 예제에서 이런 방식을 보았습니다. 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력합니다. 즉, 46차원의 출력 벡터를 만들며 `output[i]`는 어떤 샘플이 클래스 `i`에 속할 확률입니다. 46개의 값을 모두 더하면 1이 됩니다.\n",
        "\n",
        "이런 문제에 사용할 최선의 손실 함수는 `categorical_crossentropy`입니다. 이 함수는 두 확률 분포의 사이의 거리를 측정합니다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리입니다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됩니다."
      ]
    },
    {
      "metadata": {
        "id": "nbv1xXdDFyxi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QbtHAa8fFyxn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 훈련 검증\n",
        "\n",
        "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용하겠습니다:"
      ]
    },
    {
      "metadata": {
        "id": "V-wpLHr-Fyxo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e6eU4mLmFyxs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이제 20번의 에포크로 모델을 훈련시킵니다:"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "E1wPx9ryFyxu",
        "colab_type": "code",
        "outputId": "d667613b-f106-46fe-d054-cd7b2dc0b483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 2s 199us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7208 - val_acc: 0.6120\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 1s 161us/step - loss: 1.4452 - acc: 0.6879 - val_loss: 1.3459 - val_acc: 0.7060\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 1s 159us/step - loss: 1.0953 - acc: 0.7651 - val_loss: 1.1708 - val_acc: 0.7430\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.8697 - acc: 0.8165 - val_loss: 1.0793 - val_acc: 0.7590\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 1s 158us/step - loss: 0.7033 - acc: 0.8470 - val_loss: 0.9843 - val_acc: 0.7820\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 1s 154us/step - loss: 0.5665 - acc: 0.8797 - val_loss: 0.9412 - val_acc: 0.8040\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.4579 - acc: 0.9047 - val_loss: 0.9081 - val_acc: 0.8010\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 1s 154us/step - loss: 0.3695 - acc: 0.9230 - val_loss: 0.9367 - val_acc: 0.7900\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.3031 - acc: 0.9313 - val_loss: 0.8925 - val_acc: 0.8090\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 1s 155us/step - loss: 0.2538 - acc: 0.9416 - val_loss: 0.9058 - val_acc: 0.8110\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.2186 - acc: 0.9464 - val_loss: 0.9180 - val_acc: 0.8140\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 1s 154us/step - loss: 0.1871 - acc: 0.9509 - val_loss: 0.9048 - val_acc: 0.8140\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 1s 154us/step - loss: 0.1699 - acc: 0.9524 - val_loss: 0.9327 - val_acc: 0.8100\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.1534 - acc: 0.9553 - val_loss: 0.9683 - val_acc: 0.8070\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.1390 - acc: 0.9559 - val_loss: 0.9682 - val_acc: 0.8150\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 1s 154us/step - loss: 0.1314 - acc: 0.9565 - val_loss: 1.0202 - val_acc: 0.8050\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.1219 - acc: 0.9580 - val_loss: 1.0247 - val_acc: 0.7980\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 1s 151us/step - loss: 0.1195 - acc: 0.9579 - val_loss: 1.0431 - val_acc: 0.8050\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.1136 - acc: 0.9594 - val_loss: 1.0966 - val_acc: 0.7970\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 1s 151us/step - loss: 0.1112 - acc: 0.9593 - val_loss: 1.0685 - val_acc: 0.8020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5L7wt-GLFyxy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "손실과 정확도 곡선을 그려 보죠:"
      ]
    },
    {
      "metadata": {
        "id": "PKKmw-1xFyxz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ON9YcYbFyx4",
        "colab_type": "code",
        "outputId": "d7cd481c-042d-4131-8294-b804aba6b620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nawEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IMe8gilTFyx-",
        "colab_type": "code",
        "outputId": "114a3761-4c5f-4190-e7ff-638f140d7051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "plt.clf()   # 그래프를 초기화합니다\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcVNWZ//HPwyar7IuCLDFGBRWE\nFsPPfUtwJUGiIplEjUEd0WiSyaAYJUZMYoxjNIwjTnQ0thISx4UoGkUSTRyQRmkQUEAEbERsdrBB\naHh+f5xb1dVNd3V1dy29fN+v131V1b3n3nrqdvV96pxz77nm7oiIiAA0y3UAIiJSfygpiIhInJKC\niIjEKSmIiEickoKIiMQpKYiISJySghzAzJqb2U4z65vOsrlkZl82s7Sff21mZ5vZ6oTXH5jZKamU\nrcV7/beZ3Vrb9UVS0SLXAUjdmdnOhJdtgS+AfdHra9w9vybbc/d9QPt0l20K3P3IdGzHzK4Gvu3u\npyds++p0bFskGSWFRsDd4wfl6Jfo1e7+WlXlzayFu5dmIzaR6uj7WL+o+agJMLO7zOyPZva0me0A\nvm1mI8xsrpltNbP1ZvaAmbWMyrcwMzez/tHrJ6Pls8xsh5n9n5kNqGnZaPm5ZrbczLaZ2YNm9k8z\nu6KKuFOJ8RozW2lmW8zsgYR1m5vZf5jZJjNbBYxMsn8mmdn0CvOmmtl90fOrzWxZ9Hk+jH7FV7Wt\nIjM7PXre1sz+EMW2BBhWoextZrYq2u4SM7somn8s8DvglKhpbmPCvp2csP610WffZGbPmdkhqeyb\nmuznWDxm9pqZbTazT83sJwnv89Non2w3swIzO7Sypjoz+0fs7xztzzei99kM3GZmR5jZnOg9Nkb7\nrWPC+v2iz1gcLf+tmbWOYj46odwhZlZiZl2r+rxSDXfX1IgmYDVwdoV5dwF7gAsJPwTaACcAJxJq\ni18ClgMTovItAAf6R6+fBDYCeUBL4I/Ak7Uo2wPYAYyKlv0Q2AtcUcVnSSXG54GOQH9gc+yzAxOA\nJUAfoCvwRvi6V/o+XwJ2Au0Stv0ZkBe9vjAqY8CZwC7guGjZ2cDqhG0VAadHz+8F/gZ0BvoBSyuU\nvQQ4JPqbXB7F0DNadjXwtwpxPglMjp5/LYpxCNAa+E/g9VT2TQ33c0dgA/AD4CDgYGB4tOwWoBA4\nIvoMQ4AuwJcr7mvgH7G/c/TZSoHrgOaE7+NXgLOAVtH35J/AvQmf571of7aLyp8ULZsGTEl4nx8B\nz+b6/7AhTzkPQFOa/6BVJ4XXq1nvx8CfoueVHej/K6HsRcB7tSh7FfBmwjID1lNFUkgxxq8mLP9f\n4MfR8zcIzWixZedVPFBV2PZc4PLo+bnAB0nK/gW4PnqeLCmsTfxbAP+aWLaS7b4HnB89ry4pPA7c\nnbDsYEI/Up/q9k0N9/O/APOrKPdhLN4K81NJCquqiWFM7H2BU4BPgeaVlDsJ+Aiw6PVCYHS6/6+a\n0qTmo6bj48QXZnaUmb0YNQdsB+4EuiVZ/9OE5yUk71yuquyhiXF4+C8uqmojKcaY0nsBa5LEC/AU\nMDZ6fnn0OhbHBWY2L2ra2Er4lZ5sX8UckiwGM7vCzAqjJpCtwFEpbhfC54tvz923A1uA3gllUvqb\nVbOfDyMc/CuTbFl1Kn4fe5nZDDNbF8XwPxViWO3hpIZy3P2fhFrHyWZ2DNAXeLGWMQnqU2hKKp6O\n+TDhl+mX3f1g4HbCL/dMWk/4JQuAmRnlD2IV1SXG9YSDSUx1p8zOAM42s96E5q2nohjbAH8GfkFo\n2ukE/DXFOD6tKgYz+xLwEKEJpWu03fcTtlvd6bOfEJqkYtvrQGimWpdCXBUl288fA4dXsV5Vyz6P\nYmqbMK9XhTIVP9+vCGfNHRvFcEWFGPqZWfMq4ngC+DahVjPD3b+oopykQEmh6eoAbAM+jzrqrsnC\ne/4FGGpmF5pZC0I7dfcMxTgDuMnMekedjv+erLC7f0po4vgfQtPRimjRQYR27mJgn5ldQGj7TjWG\nW82sk4XrOCYkLGtPODAWE/Lj9wk1hZgNQJ/EDt8Knga+Z2bHmdlBhKT1prtXWfNKItl+fgHoa2YT\nzOwgMzvYzIZHy/4buMvMDrdgiJl1ISTDTwknNDQ3s/EkJLAkMXwObDOzwwhNWDH/B2wC7rbQed/G\nzE5KWP4HQnPT5YQEIXWgpNB0/Qj4LqHj92FCh3BGufsG4FLgPsI/+eHAu4RfiOmO8SFgNrAYmE/4\ntV+dpwh9BPGmI3ffCtwMPEvorB1DSG6puINQY1kNzCLhgOXui4AHgbejMkcC8xLWfRVYAWwws8Rm\noNj6LxOaeZ6N1u8LjEsxroqq3M/uvg04B7iYkKiWA6dFi38NPEfYz9sJnb6to2bB7wO3Ek46+HKF\nz1aZO4DhhOT0AvBMQgylwAXA0YRaw1rC3yG2fDXh7/yFu79Vw88uFcQ6Z0SyLmoO+AQY4+5v5joe\nabjM7AlC5/XkXMfS0OniNckqMxtJONNnF+GUxr2EX8sitRL1z4wCjs11LI2Bmo8k204GVhHa0r8O\nfFMdg1JbZvYLwrUSd7v72lzH0xio+UhEROJUUxARkbgG16fQrVs379+/f67DEBFpUBYsWLDR3ZOd\nAg40wKTQv39/CgoKch2GiEiDYmbVXdUPqPlIREQSKCmIiEickoKIiMQpKYiISJySgoiIxCkpiIhk\nWH4+9O8PzZqFx/z87K5fE0oKIlLv5fqgWpf18/Nh/HhYswbcw+P48alvo67r11iub/1W02nYsGEu\nItn15JPu/fq5m4XHJ5/M3vpPPunetq17OCSGqW3b1LeR6/X79Su/bmzq1y8768cABZ7CMTbnB/ma\nTkoKIjXXkA/KuT6o1nV9s8rXN8vO+jFKCiKNSC4P6k39oFrX9XO9/2JSTQrqUxCp5+rapjxpEpSU\nlJ9XUhLmp2JtFQNSVzU/3ev3reLu2lXNr2/rT5kCbduWn9e2bZifjfVrLJXMUZ8m1RSkoalre3yu\nf2nn+pdurpuv6rp+bBu56pOJQc1HIrmXjgNKrg/qOqim56Cca0oKImlSlwNCOtqDc31Qj22jqR9U\nGzolBZE0qOsBNR1njtSHg7o0fKkmhQZ3O868vDzX/RQkW/r3Dx27FfXrB6tXZ379mPz80DG8dm3o\n4JwyBcaNS319ETNb4O551ZXT2UciSdT1zJl0nTkyblxIIvv3h0clBMkUJQVp9OoyREFdT0ccNw6m\nTQs1A7PwOG2aDupSfykpSKNW13P80/FLX7/ypSFRUpBGra4XbumXvjQ16miWRq1Zs1BDqMgs/HIX\naSrU0SyNRi77BESaGiUFqdfqQ5+ASFOipCD1mvoERLJLfQpSr6lPQCQ91KcgjYL6BESyS0lB6jX1\nCYhkl5KC1GvqExDJrha5DkCkOuPGKQmIZItqCpJxdbnOQESyK6NJwcxGmtkHZrbSzCZWsryfmc02\ns0Vm9jcz65PJeCT76nqdgYhkV8aSgpk1B6YC5wIDgbFmNrBCsXuBJ9z9OOBO4BeZikdyo67XGYhI\ndmWypjAcWOnuq9x9DzAdGFWhzEDg9ej5nEqWSwNX1/sRiEh2ZTIp9AY+TnhdFM1LVAiMjp5/E+hg\nZl0zGJNkma4zEGlYct3R/GPgNDN7FzgNWAfsq1jIzMabWYGZFRQXF2c7RqkDXWcg0rBkMimsAw5L\neN0nmhfn7p+4+2h3Px6YFM3bWnFD7j7N3fPcPa979+4ZDFnSTdcZiDQsmbxOYT5whJkNICSDy4DL\nEwuYWTdgs7vvB24BHs1gPJIjus5ApOHIWE3B3UuBCcArwDJghrsvMbM7zeyiqNjpwAdmthzoCahR\nQUQkhzRKqohIE6BRUiVtdEWySNOhsY8kqdgVybEL0GJXJIP6CUQaI9UUJCldkSzStCgpSFK6Ilmk\naVFSkKR0RbJI06KkIEnpimSRpkVJQZLSFckiTYvOPpJq6YpkkaZDNQUREYlTUhARkTglBRERiVNS\nEBGROCUFERGJU1IQEZE4JYUmQKOcikiqdJ1CI6dRTkWkJlRTaOQ0yqmI1ISSQiOnUU5FpCaUFBo5\njXIqIjWhpNDIaZRTEakJJYVGTqOcikhN6OyjJkCjnIpIqlRTEBGROCUFERGJU1IQEZE4JQUREYlT\nUhARkTglhQZAA9qJSLbolNR6TgPaiUg2qaZQz2lAOxHJJtUU6jkNaNew7N8PW7ZAcTFs3Bim2PMt\nW8Ly2mrWDHr2hN69oU+f8HjooXDQQemLP13cYfVqmDcP3n47TEuXwrHHwtlnwznnQF4etNARqN7R\nn6Se69s3NBlVNl8yZ98+2LEDtm8P044dsG3bgQf6xOfFxbB5c9UH/tatoXnz2sdUWgpffHHg/G7d\nypJE4pQ4r1OnMMxJpmzeXHbwj03FxWFZ69YwbBhcfDG88w7ccQfcfjscfDCccUZIEmefDUcemdkY\nJTVKCvXclCnl+xRAA9rVRnExPPMMbNpUdrCveNBPfF6xya6i5s3DwTg2DRpU9rx79/KPsalNm7p9\nBveQmNatg6Ki8Jg4FRWVPxgnatMmJIcePQ6MrbLnHTpUfYDevRsWLiw7+M+bBytXhmVmcPTRcMEF\nMHw4nHgiHHMMtGxZtv7GjTBnDrz2Wpiefz7M7927LEGcdRYcckjd9pfUjrl7rmOokby8PC8oKMh1\nGFmVnx/6ENauDTWEKVPUyZyqTZvg3nvhwQfh88/DvJYtw6/U2NShQ+rPYwfOjh1Dc0599MUXsH59\n5ckjsXZTXAx791a+jVatDkwU7drBokVQWFi23iGHhAP/iSeGJJCXF/ZTTaxaBbNnw6uvhsfNm8P8\nQYNCM9PZZ8Opp4a/gdSemS1w97xqy2UyKZjZSOC3QHPgv939lxWW9wUeBzpFZSa6+0vJttkUk0J9\nsHs3zJ0L7duXHSjatq2/1f3Nm+G+++C3vw3J4NJL4dZb4StfqZ9t8LngHmpFyZrDEudt3x5qAbEa\nwPDhoYkqnfbvD7WQWC3izTfDd69Fi/CeJ5wAQ4aE6eijQ/LKlH374MMPQzwLF8IHH8CAAWWfv2/f\n+vv9r0zOk4KZNQeWA+cARcB8YKy7L00oMw14190fMrOBwEvu3j/ZdpUUsssdZs6EH/4w/IMkat26\n6uaSivO6d4cuXTLfsbhlC/zHf4RksH07XHJJaL8eNCiz7yuZsXs3vPVWSBCvvx5qKrt2hWUtW8LA\ngWVJYvDgMHXpUvP3+fxzWLw4HPwLC8PjokVlzYgtWoSEsHZtWb9Oz54hQcSSxAknhL6bdNq9O3TY\nr1oVptNPD81xtZFqUsjkv+hwYKW7r4oCmg6MApYmlHEgVtnsCHySwXikht5/H266CV55JfwqmzEj\n/Mqu6pflqlVlvygr06oVnHYanH9+mL785fTFum0b3H9/SAjbtoVOzTvuCGe7SMPVujWceWaYIPx6\nX7Gi7Nd7YWH4fj7+eNk6ffuG5JCYLAYMCM197vDpp2Xrx7axfHlYBqFpcMgQuPrqsm0MHBi++3v2\nhGQR60t5++3woynmyCPL16QGD05em3GHDRvKDvoVp3Xrype///7aJ4VUZbKmMAYY6e5XR6//BTjR\n3ScklDkE+CvQGWgHnO3uCyrZ1nhgPEDfvn2HransdBxJm23b4Oc/D7+227WDn/0M/vVfy3cWJrNn\nT1nCSEwaH34Is2aFZAOhKSeWIE45pXZNAdu3wwMPwG9+A1u3wje+AZMnh39GaTo2bCj7hR870L//\nftmZYB06hAP2mjXlO+IHDDgwgcRuSJWqrVuhoKAsScybF+KB8J0+/viQJI4/PnxfKx74YzWfmD59\n4Etfqnzq0aP2TVb1ofkolaTwwyiG35jZCOD3wDHuXuXZ3Go+ypz9+8MvrokTwz/O974XOrV79Ejv\n+6xaBS++GKY5c0IS6dAhdCqefz6cdx706pV8Gzt2hM7j3/wm9B9ceGFIBkOHpjdWabh27YL33itL\nFu+/Hw74sSRw3HHpb+6B8Ov/44/LJ4kFC8qaotq1q/yAf/jhIb7WrdMfE6SeFHD3jEzACOCVhNe3\nALdUKLMEOCzh9SqgR7LtDhs2zCX95s51Hz7cHdxHjHAvKMjO++7c6f788+7jx7v37h3eH9yHDXO/\n/Xb3efPc9+0rK79jh/svf+netWsod/757vPnZydWkdrau9d92TL3DRvc9+/PTQxAgadw7M5kTaEF\noaP5LGAdoaP5cndfklBmFvBHd/8fMzsamA309iRBqaaQXp9+GmoGjz8eTi+8555wumsuzqpwD+21\nsVrE3Lmh9tK9O5x7bhgM8D//MzRFjRwZmrWGD89+nCINUc6bj6IgzgPuJ5xu+qi7TzGzOwkZ64Xo\njKNHgPaETuefuPtfk21TSSE99uwJbfF33hnOcPjhD8O1EPXpXPBNm+Dll0OCePnlcGbROeeEZDBi\nRK6jE2lY6kVSyAQlhbqbNSucVbR8ebjy9L774Igjch1VcqWlofOud+9cRyLSMKWaFOrpNZmSCStX\nhg7Z884LTTUvvhhOp6vvCQHCeeJKCCKZp6TQBJSUwG23hQu4/va30G/w3nshOYiIJNKAeI3ciy/C\nhAnhqshvfzskBA00JiJVUU2hkfr4Yxg9OvQZtGkTrgf4wx+UEEQkOSWFRmbvXvj1r8OwFC+/DL/4\nRbhw5/TTcx2ZiDQE1SYFM7vBzDpnIxipmzffDJfS/+QnYayYpUvDNQiZHElSRBqXVGoKPYH5ZjbD\nzEaaNaTBYuuH/Pxw4VWzZuExPz+92y8uhiuvDGPO79gRblrywgvhvUREaqLapODutwFHEMYlugJY\nYWZ3m9nhGY6tUcjPD3dOW7MmnAa6Zk14nY7EsH8/TJsWBvp68slQK1i6FC66qO7bFpGmKaU+hWjY\niU+jqZQwqumfzeyeDMbWKEyadOCtHUtKwvy6WLgQTjoJrrkmDOxVWBj6D9q1q9t2RaRpS6VP4Qdm\ntgC4B/gncKy7XwcMAy7OcHwN3tq1NZtfne3bw9XIw4aFoaifeCKcWTRwYO1jFBGJSeU6hS7AaHcv\ndxMDd99vZhdkJqzGo2/f0GRU2fyacIc//Qluvjncf/eaa+Duu6GzTgEQkTRKpfloFrA59sLMDjaz\nEwHcfVmmAmsspkwJ9zJO1LZtmJ+KkhJ45JEw/vull4b7DMydCw89pIQgIumXSlJ4CNiZ8HpnNE9S\nMG5c6AyO3c2pX7/wety45Ot99BH827+FuzCNHx/m/f734aYdGi5aRDIlleYjS7y/QdRspOExamDc\nuOqTAIQmotmzwx3FZs4Mp7COHg033AAnn5ybexyISNOSysF9lZndSFnt4F8Jd0iTNNm5M3QY/+53\nsGxZuKnMrbfCtdeGmoKISLakkhSuBR4AbiPcCGc2MD6TQTUVK1bA1Knw2GPhrKK8vHAHtEsuydx9\nWkVEkqk2Kbj7Z8BlWYilSdi/H155JTQRzZoFLVvCt74VmohOPFFNRCKSW9UmBTNrDXwPGATEf7+6\n+1UZjKvR2bUrdDBPnRpqCL16weTJ4dTSXr1yHZ2ISJDK2Ud/AHoBXwf+DvQBdmQyqMZm585wQ5ub\nboJu3eCpp8K1C3fcoYQgIvVLKn0KX3b3b5nZKHd/3MyeAt7MdGCNxY4dcP758M9/hvsZfPvbuY5I\nRKRqqSSFvdHjVjM7hjD+UY/MhdR4bN8O554L8+aF2sGll+Y6IhGR5FJJCtOi+yncBrwAtAd+mtGo\nGoFt2+DrX4cFC2D6dBgzJtcRiYhUL2lSMLNmwHZ33wK8AXwpK1E1cFu2hISwcGEYr+gb38h1RCIi\nqUna0ezu+4GfZCmWRmHTJjj77DCU9TPPKCGISMOSytlHr5nZj83sMDPrEpsyHlkDtHEjnHUWLFkC\nzz4LF16Y64hERGomlT6FWPfo9QnzHDUllfPZZ6GGsHx5uB3m17+e64hERGoulSuaB2QjkIZswwY4\n88wwsulf/hKSg4hIQ5TKFc3fqWy+uz+R/nAanvXrQ0JYuxZefBHOOCPXEYmI1F4qzUcnJDxvDZwF\nvAM0+aSwbl1ICOvWhXGMTj011xGJiNRNKs1HNyS+NrNOwPSMRdRAfPxxqBVs2BAGuDvppFxHJCJS\nd7W5Wc7nQJPuZ1izJiSETZvgr3+FESNyHZGISHqk0qcwk3C2EYRTWAcCMzIZVH320UchIWzdCq++\nqltjikjjkkpN4d6E56XAGncvylA89dqHH4aEsHNnuG3msGG5jkhEJL1SSQprgfXuvhvAzNqYWX93\nX53RyOqZ1avhtNNg9254/XUYMiTXEYmIpF8qVzT/Cdif8HpfNK9aZjbSzD4ws5VmNrGS5f9hZguj\nabmZbU0t7Oy7664wppESgog0ZqnUFFq4+57YC3ffY2atqlvJzJoDU4FzgCJgvpm94O5LE7Z1c0L5\nG4DjaxJ8tmzfDk8/DZdfDscdl+toREQyJ5WaQrGZXRR7YWajgI0prDccWOnuq6KkMh0YlaT8WODp\nFLabdfn5UFIC48fnOhIRkcxKpaZwLZBvZr+LXhcBlV7lXEFv4OOE10XAiZUVNLN+hNNcX69i+Xhg\nPEDfvn1TeOv0cYeHH4bjj4e8vKy+tYhI1qVy8dqHwFfNrH30emcG4rgM+LO776sihmnANIC8vDyv\nrEymzJ8fhsF+6CEwy+Y7i4hkX7XNR2Z2t5l1cved7r7TzDqb2V0pbHsdcFjC6z7RvMpcRj1tOpo2\nDQ46CO6+G5o1g/79Q3OSiEhjlEqfwrnuHj8rKLoL23kprDcfOMLMBkQd05cRbudZjpkdBXQG/i+1\nkLNn+3Z48kkoLQ3DWriHq5nHj1diEJHGKZWk0NzMDoq9MLM2wEFJygPg7qXABOAVYBkww92XmNmd\niR3XhGQx3d2z2iyUivx8+OIL2FehUaukBCZNyk1MIiKZlEpHcz4w28weAwy4Ang8lY27+0vASxXm\n3V7h9eRUtpVtsQ7mqqxdm71YRESyJZWO5l+ZWSFwNmEMpFeAfpkOLNdiHcxdusDmzQcuz/JJUCIi\nWZFK8xHABkJC+BZwJqE5qFGbNg3atYNf/hLati2/rG1bmDIlN3GJiGRSlTUFM/sK4YKysYSL1f4I\nmLs3+nuLJV7B/P3vhyQwaVJoMurbNySEceNyHaWISPolaz56H3gTuMDdVwKY2c1JyjcaFa9gHjdO\nSUBEmoZkzUejgfXAHDN7xMzOInQ0N2q6gllEmrIqk4K7P+fulwFHAXOAm4AeZvaQmX0tWwFmW6yD\nefx4XcEsIk1PtR3N7v65uz/l7hcSrkp+F/j3jEeWI7EO5ssvz3UkIiLZl+rZR0C4mtndp7n7WZkK\nKJdiHcxjx8LBB+c6GhGR7KtRUmjsNES2iDR1SgqRWAfzkCHqYBaRpktJIRLrYL7mGnUwi0jTpaQQ\nUQeziIiSAqAOZhGRGCUF1MEsIhLT5JOCOphFRMo0+aSgDmYRkTJNPimog1lEpEyTTgrqYBYRKa9J\nJwV1MIuIlNdkk4I6mEVEDtRkk4I6mEVEDtRkk8K0aeE2m+pgFhEp0ySTgjqYRUQq1ySTQqyD+Zpr\nch2JiEj90uSSgjqYRUSq1uSSgjqYRUSq1uSSgjqYRUSq1qSSgjqYRUSSa1JJQR3MIiLJNZmkoA5m\nEZHqNZmkoA5mEZHqNZmkMHu2hsgWEalOk0kKt9wCH36oDmYRkWQymhTMbKSZfWBmK81sYhVlLjGz\npWa2xMyeymQ8PXtmcusiIg1fi0xt2MyaA1OBc4AiYL6ZveDuSxPKHAHcApzk7lvMrEem4hERkepl\nsqYwHFjp7qvcfQ8wHRhVocz3ganuvgXA3T/LYDwiIlKNTCaF3sDHCa+LonmJvgJ8xcz+aWZzzWxk\nZRsys/FmVmBmBcXFxRkKV0REct3R3AI4AjgdGAs8YmadKhZy92nunufued27d89yiCIiTUcmk8I6\n4LCE132ieYmKgBfcfa+7fwQsJyQJERHJgUwmhfnAEWY2wMxaAZcBL1Qo8xyhloCZdSM0J63KYEwi\nIpJExpKCu5cCE4BXgGXADHdfYmZ3mtlFUbFXgE1mthSYA/ybu2/KVEwiIpKcuXuuY6iRvLw8Lygo\nyHUYIiINipktcPdqR37LdUeziIjUI0oKIiISp6QgIiJxSgoiIhKnpCAiInFKCiIiEqekICIicUoK\nIiISp6QgIiJxSgoiIhKnpCAiInEZux2niDQue/fupaioiN27d+c6FEmidevW9OnTh5YtW9ZqfSUF\nEUlJUVERHTp0oH///phZrsORSrg7mzZtoqioiAEDBtRqG2o+EpGU7N69m65duyoh1GNmRteuXetU\nm1NSEJGUKSHUf3X9GykpiIhInJKCiGREfj707w/NmoXH/Py6bW/Tpk0MGTKEIUOG0KtXL3r37h1/\nvWfPnpS2ceWVV/LBBx8kLTN16lTy6xpsA6aOZhFJu/x8GD8eSkrC6zVrwmuAceNqt82uXbuycOFC\nACZPnkz79u358Y9/XK6Mu+PuNGtW+e/dxx57rNr3uf7662sXYCOhmoKIpN2kSWUJIaakJMxPt5Ur\nVzJw4EDGjRvHoEGDWL9+PePHjycvL49BgwZx5513xsuefPLJLFy4kNLSUjp16sTEiRMZPHgwI0aM\n4LPPPgPgtttu4/7774+XnzhxIsOHD+fII4/krbfeAuDzzz/n4osvZuDAgYwZM4a8vLx4wkp0xx13\ncMIJJ3DMMcdw7bXXErv98fLlyznzzDMZPHgwQ4cOZfXq1QDcfffdHHvssQwePJhJmdhZKVBSEJG0\nW7u2ZvPr6v333+fmm29m6dKl9O7dm1/+8pcUFBRQWFjIq6++ytKlSw9YZ9u2bZx22mkUFhYyYsQI\nHn300Uq37e68/fbb/PrXv44nmAcffJBevXqxdOlSfvrTn/Luu+9Wuu4PfvAD5s+fz+LFi9m2bRsv\nv/wyAGPHjuXmm2+msLCQt956ix49ejBz5kxmzZrF22+/TWFhIT/60Y/StHdqRklBRNKub9+aza+r\nww8/nLy8snvSP/300wwdOpShQ4eybNmySpNCmzZtOPfccwEYNmxY/Nd6RaNHjz6gzD/+8Q8uu+wy\nAAYPHsygQYMqXXf27NkMHz5GTBHFAAAOwklEQVScwYMH8/e//50lS5awZcsWNm7cyIUXXgiEi83a\ntm3La6+9xlVXXUWbNm0A6NKlS813RBooKYhI2k2ZAm3blp/Xtm2Ynwnt2rWLP1+xYgW//e1vef31\n11m0aBEjR46s9Lz9Vq1axZ83b96c0tLSSrd90EEHVVumMiUlJUyYMIFnn32WRYsWcdVVVzWIq8GV\nFEQk7caNg2nToF8/MAuP06bVvpO5JrZv306HDh04+OCDWb9+Pa+88kra3+Okk05ixowZACxevLjS\nmsiuXbto1qwZ3bp1Y8eOHTzzzDMAdO7cme7duzNz5kwgXBRYUlLCOeecw6OPPsquXbsA2Lx5c9rj\nToXOPhKRjBg3LjtJoKKhQ4cycOBAjjrqKPr168dJJ52U9ve44YYb+M53vsPAgQPjU8eOHcuV6dq1\nK9/97ncZOHAghxxyCCeeeGJ8WX5+Ptdccw2TJk2iVatWPPPMM1xwwQUUFhaSl5dHy5YtufDCC/n5\nz3+e9tirY7He8IYiLy/PCwoKch2GSJOzbNkyjj766FyHUS+UlpZSWlpK69atWbFiBV/72tdYsWIF\nLVrUj9/Zlf2tzGyBu+dVsUpc/fgEIiINyM6dOznrrLMoLS3F3Xn44YfrTUKoq8bxKUREsqhTp04s\nWLAg12FkhDqaRUQkTklBRETilBRERCROSUFEROKUFESkQTjjjDMOuBDt/vvv57rrrku6Xvv27QH4\n5JNPGDNmTKVlTj/9dKo71f3++++nJGGUv/POO4+tW7emEnqDoqQgIg3C2LFjmT59erl506dPZ+zY\nsSmtf+ihh/LnP/+51u9fMSm89NJLdOrUqdbbq690SqqI1NhNN0ElI0XXyZAhEI1YXakxY8Zw2223\nsWfPHlq1asXq1av55JNPOOWUU9i5cyejRo1iy5Yt7N27l7vuuotRo0aVW3/16tVccMEFvPfee+za\ntYsrr7ySwsJCjjrqqPjQEgDXXXcd8+fPZ9euXYwZM4af/exnPPDAA3zyySecccYZdOvWjTlz5tC/\nf38KCgro1q0b9913X3yU1auvvpqbbrqJ1atXc+6553LyySfz1ltv0bt3b55//vn4gHcxM2fO5K67\n7mLPnj107dqV/Px8evbsyc6dO7nhhhsoKCjAzLjjjju4+OKLefnll7n11lvZt28f3bp1Y/bs2en7\nI5DhmoKZjTSzD8xspZlNrGT5FWZWbGYLo+nqTMYjIg1Xly5dGD58OLNmzQJCLeGSSy7BzGjdujXP\nPvss77zzDnPmzOFHP/oRyUZreOihh2jbti3Lli3jZz/7WblrDqZMmUJBQQGLFi3i73//O4sWLeLG\nG2/k0EMPZc6cOcyZM6fcthYsWMBjjz3GvHnzmDt3Lo888kh8KO0VK1Zw/fXXs2TJEjp16hQf/yjR\nySefzNy5c3n33Xe57LLLuOeeewD4+c9/TseOHVm8eDGLFi3izDPPpLi4mO9///s888wzFBYW8qc/\n/anO+7WijNUUzKw5MBU4BygC5pvZC+5eceSoP7r7hEzFISLpl+wXfSbFmpBGjRrF9OnT+f3vfw+E\nex7ceuutvPHGGzRr1ox169axYcMGevXqVel23njjDW688UYAjjvuOI477rj4shkzZjBt2jRKS0tZ\nv349S5cuLbe8on/84x9885vfjI/UOnr0aN58800uuugiBgwYwJAhQ4Cqh+cuKiri0ksvZf369ezZ\ns4cBAwYA8Nprr5VrLuvcuTMzZ87k1FNPjZfJxPDamawpDAdWuvsqd98DTAdGVbNORqT7XrEikhuj\nRo1i9uzZvPPOO5SUlDBs2DAgDDBXXFzMggULWLhwIT179qzVMNUfffQR9957L7Nnz2bRokWcf/75\ndRruOjbsNlQ99PYNN9zAhAkTWLx4MQ8//HDOh9fOZFLoDXyc8LoomlfRxWa2yMz+bGaHVbYhMxtv\nZgVmVlBcXFyjIGL3il2zBtzL7hWrxCDS8LRv354zzjiDq666qlwH87Zt2+jRowctW7Zkzpw5rFmz\nJul2Tj31VJ566ikA3nvvPRYtWgSEYbfbtWtHx44d2bBhQ7ypCqBDhw7s2LHjgG2dcsopPPfcc5SU\nlPD555/z7LPPcsopp6T8mbZt20bv3uHQ+Pjjj8fnn3POOUydOjX+esuWLXz1q1/ljTfe4KOPPgIy\nM7x2rs8+mgn0d/fjgFeBxysr5O7T3D3P3fO6d+9eozfI5r1iRSTzxo4dS2FhYbmkMG7cOAoKCjj2\n2GN54oknOOqoo5Ju47rrrmPnzp0cffTR3H777fEax+DBgzn++OM56qijuPzyy8sNuz1+/HhGjhzJ\nGWecUW5bQ4cO5YorrmD48OGceOKJXH311Rx//PEpf57JkyfzrW99i2HDhtGtW7f4/Ntuu40tW7Zw\nzDHHMHjwYObMmUP37t2ZNm0ao0ePZvDgwVx66aUpv0+qMjZ0tpmNACa7+9ej17cAuPsvqijfHNjs\n7h0rWx5T06GzmzULNYQD3w/27095MyJNnobObjjqMnR2JmsK84EjzGyAmbUCLgNeSCxgZockvLwI\nWJbuILJ9r1gRkYYsY0nB3UuBCcArhIP9DHdfYmZ3mtlFUbEbzWyJmRUCNwJXpDuObN8rVkSkIcvo\nxWvu/hLwUoV5tyc8vwW4JZMxxG4HOGkSrF0baghTpuTmNoEiDZ27Y2a5DkOSqGuXQJO4ojlX94oV\naUxat27Npk2b6Nq1qxJDPeXubNq0idatW9d6G00iKYhI3fXp04eioiJqelq4ZFfr1q3p06dPrddX\nUhCRlLRs2TJ+Ja00Xrm+TkFEROoRJQUREYlTUhARkbiMXdGcKWZWDCQf2CR3ugEbcx1EEoqvbup7\nfFD/Y1R8dVOX+Pq5e7XjBDW4pFCfmVlBKpeR54riq5v6Hh/U/xgVX91kIz41H4mISJySgoiIxCkp\npNe0XAdQDcVXN/U9Pqj/MSq+usl4fOpTEBGRONUUREQkTklBRETilBRqyMwOM7M5ZrY0uhfEDyop\nc7qZbTOzhdF0e2XbymCMq81scfTeB9ymzoIHzGxldH/soVmM7ciE/bLQzLab2U0VymR9/5nZo2b2\nmZm9lzCvi5m9amYrosfOVaz73ajMCjP7bpZi+7WZvR/9/Z41s05VrJv0u5DhGCeb2bqEv+N5Vaw7\n0sw+iL6PE7MY3x8TYlttZgurWDej+7CqY0rOvn/urqkGE3AIMDR63gFYDgysUOZ04C85jHE10C3J\n8vOAWYABXwXm5SjO5sCnhItqcrr/gFOBocB7CfPuASZGzycCv6pkvS7Aquixc/S8cxZi+xrQInr+\nq8piS+W7kOEYJwM/TuE78CHwJaAVUFjx/ylT8VVY/hvg9lzsw6qOKbn6/qmmUEPuvt7d34me7yDc\nVa53bqOqsVHAEx7MBTpVuDVqtpwFfOjuOb9C3d3fADZXmD0KeDx6/jjwjUpW/TrwqrtvdvctwKvA\nyEzH5u5/9XB3Q4C5QO3HSk6DKvZfKoYDK919lbvvAaYT9ntaJYvPws0hLgGeTvf7piLJMSUn3z8l\nhTows/7A8cC8ShaPMLNCM5tlZoOyGhg48FczW2Bm4ytZ3hv4OOF1EblJbJdR9T9iLvdfTE93Xx89\n/xToWUmZ+rAvryLU/CpT3Xch0yZETVyPVtH8UR/23ynABndfUcXyrO3DCseUnHz/lBRqyczaA88A\nN7n79gqL3yE0iQwGHgSey3J4J7v7UOBc4HozOzXL718tM2sFXAT8qZLFud5/B/BQV69352+b2SSg\nFMivokguvwsPAYcDQ4D1hCaa+mgsyWsJWdmHyY4p2fz+KSnUgpm1JPzx8t39fysud/ft7r4zev4S\n0NLMumUrPndfFz1+BjxLqKInWgcclvC6TzQvm84F3nH3DRUX5Hr/JdgQa1aLHj+rpEzO9qWZXQFc\nAIyLDhoHSOG7kDHuvsHd97n7fuCRKt47p99FM2sBjAb+WFWZbOzDKo4pOfn+KSnUUNT++Htgmbvf\nV0WZXlE5zGw4YT9vylJ87cysQ+w5oUPyvQrFXgC+E52F9FVgW0I1NVuq/HWWy/1XwQtA7GyO7wLP\nV1LmFeBrZtY5ah75WjQvo8xsJPAT4CJ3L6miTCrfhUzGmNhP9c0q3ns+cISZDYhqj5cR9nu2nA28\n7+5FlS3Mxj5MckzJzfcvUz3qjXUCTiZU4xYBC6PpPOBa4NqozARgCeFMirnA/8tifF+K3rcwimFS\nND8xPgOmEs76WAzkZXkftiMc5DsmzMvp/iMkqPXAXkK77PeArsBsYAXwGtAlKpsH/HfCulcBK6Pp\nyizFtpLQlhz7Dv5XVPZQ4KVk34Us7r8/RN+vRYQD3CEVY4xen0c44+bDTMVYWXzR/P+Jfe8SymZ1\nHyY5puTk+6dhLkREJE7NRyIiEqekICIicUoKIiISp6QgIiJxSgoiIhKnpCASMbN9Vn4E17SN2Glm\n/RNH6BSpr1rkOgCRemSXuw/JdRAiuaSagkg1ovH074nG1H/bzL4cze9vZq9HA77NNrO+0fyeFu5x\nUBhN/y/aVHMzeyQaM/+vZtYmKn9jNJb+IjObnqOPKQIoKYgkalOh+ejShGXb3P1Y4HfA/dG8B4HH\n3f04woB0D0TzHwD+7mFAv6GEK2EBjgCmuvsgYCtwcTR/InB8tJ1rM/XhRFKhK5pFIma2093bVzJ/\nNXCmu6+KBi771N27mtlGwtANe6P56929m5kVA33c/YuEbfQnjHt/RPT634GW7n6Xmb0M7CSMBvuc\nR4MBiuSCagoiqfEqntfEFwnP91HWp3c+YSyqocD8aOROkZxQUhBJzaUJj/8XPX+LMKonwDjgzej5\nbOA6ADNrbmYdq9qomTUDDnP3OcC/Ax2BA2orItmiXyQiZdpY+Zu3v+zusdNSO5vZIsKv/bHRvBuA\nx8zs34Bi4Mpo/g+AaWb2PUKN4DrCCJ2VaQ48GSUOAx5w961p+0QiNaQ+BZFqRH0Kee6+MdexiGSa\nmo9ERCRONQUREYlTTUFEROKUFEREJE5JQURE4pQUREQkTklBRETi/j/TQR6PAvwbOwAAAABJRU5E\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DwukfW0VFyyD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 모델은 9번째 에포크 이후에 과대적합이 시작됩니다. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다:"
      ]
    },
    {
      "metadata": {
        "id": "gOjFVW0lFyyE",
        "colab_type": "code",
        "outputId": "0d70be21-59d3-406a-fc7c-f33221afa1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=9,\n",
        "          batch_size=512,\n",
        "          validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/9\n",
            "7982/7982 [==============================] - 1s 180us/step - loss: 2.5398 - acc: 0.5226 - val_loss: 1.6733 - val_acc: 0.6570\n",
            "Epoch 2/9\n",
            "7982/7982 [==============================] - 1s 151us/step - loss: 1.3711 - acc: 0.7119 - val_loss: 1.2756 - val_acc: 0.7190\n",
            "Epoch 3/9\n",
            "7982/7982 [==============================] - 1s 151us/step - loss: 1.0137 - acc: 0.7786 - val_loss: 1.1301 - val_acc: 0.7520\n",
            "Epoch 4/9\n",
            "7982/7982 [==============================] - 1s 150us/step - loss: 0.7975 - acc: 0.8252 - val_loss: 1.0532 - val_acc: 0.7580\n",
            "Epoch 5/9\n",
            "7982/7982 [==============================] - 1s 151us/step - loss: 0.6391 - acc: 0.8629 - val_loss: 0.9759 - val_acc: 0.7940\n",
            "Epoch 6/9\n",
            "7982/7982 [==============================] - 1s 152us/step - loss: 0.5111 - acc: 0.8923 - val_loss: 0.9094 - val_acc: 0.8140\n",
            "Epoch 7/9\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.4108 - acc: 0.9147 - val_loss: 0.8912 - val_acc: 0.8200\n",
            "Epoch 8/9\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.3346 - acc: 0.9287 - val_loss: 0.8732 - val_acc: 0.8270\n",
            "Epoch 9/9\n",
            "7982/7982 [==============================] - 1s 153us/step - loss: 0.2776 - acc: 0.9367 - val_loss: 0.9367 - val_acc: 0.8010\n",
            "2246/2246 [==============================] - 0s 121us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vy6DWYNUFyyH",
        "colab_type": "code",
        "outputId": "6bb82bbb-c485-4af0-f63e-25d9d86b959c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.023759309245557, 0.7760463045944832]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "7ja-Om0aFyyK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "대략 78%의 정확도를 달성했습니다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 19% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다:"
      ]
    },
    {
      "metadata": {
        "id": "hMBX_RFSFyyL",
        "colab_type": "code",
        "outputId": "17dac88f-2f6f-4bcd-f9d2-50f0ec699f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.182546749777382"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "7D5xEtddFyyS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 새로운 데이터에 대해 예측하기\n",
        "\n",
        "모델 인스턴스의 `predict` 메서드는 46개 토픽에 대한 확률 분포를 반환합니다. 테스트 데이터 전체에 대한 토픽을 예측해 보겠습니다:"
      ]
    },
    {
      "metadata": {
        "id": "m-aWfAPBFyyT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LadmPAOxFyyW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`predictions`의 각 항목은 길이가 46인 벡터입니다:"
      ]
    },
    {
      "metadata": {
        "id": "y8Zwa5FmFyyX",
        "colab_type": "code",
        "outputId": "68c6c07a-a519-4a7e-893c-e12eb02c61a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "predictions[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "gfM7W3UyFyyd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 벡터의 원소 합은 1입니다:"
      ]
    },
    {
      "metadata": {
        "id": "VWqjAjybFyye",
        "colab_type": "code",
        "outputId": "dc108f1d-3edf-4fbf-ec2d-888e67abb49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "np.sum(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "g3Ok9g8bFyyh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "가장 큰 값이 예측 클래스가 됩니다. 즉, 가장 확률이 높은 클래스입니다:"
      ]
    },
    {
      "metadata": {
        "id": "LXvdJMY8Fyyi",
        "colab_type": "code",
        "outputId": "e1c13051-f178-4213-8f6d-8ca73220c04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "7wwaIj1tFyyo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 레이블과 손실을 다루는 다른 방법\n",
        "\n",
        "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것입니다:"
      ]
    },
    {
      "metadata": {
        "id": "z85hmHqhFyyr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XjYKFDbEFyyu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 방식을 사용하려면 손실 함수 하나만 바꾸면 됩니다. 코드 3-21에 사용된 손실 함수 `categorical_crossentropy`는 레이블이 범주형 인코딩되어 있을 것이라고 기대합니다. 정수 레이블을 사용할 때는 `sparse_categorical_crossentropy`를 사용해야 합니다:"
      ]
    },
    {
      "metadata": {
        "id": "4G1WQ2wBFyyw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s-FTBCGLFyy1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 `categorical_crossentropy`와 동일합니다."
      ]
    },
    {
      "metadata": {
        "id": "c2YZjaBgFyy1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 충분히 큰 중간층을 두어야 하는 이유\n",
        "\n",
        "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 됩니다. 46차원보다 훨씬 작은 중간층(예를 들면 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해 보겠습니다."
      ]
    },
    {
      "metadata": {
        "id": "Hg6gLA5dFyy2",
        "colab_type": "code",
        "outputId": "9ffca44c-5eb6-4bbf-e68c-21cd747a4c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(4, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7982 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "7982/7982 [==============================] - 2s 251us/step - loss: 2.6582 - acc: 0.3775 - val_loss: 1.9683 - val_acc: 0.5310\n",
            "Epoch 2/20\n",
            "7982/7982 [==============================] - 2s 215us/step - loss: 1.6666 - acc: 0.6210 - val_loss: 1.5413 - val_acc: 0.6250\n",
            "Epoch 3/20\n",
            "7982/7982 [==============================] - 2s 219us/step - loss: 1.3339 - acc: 0.6701 - val_loss: 1.3941 - val_acc: 0.6830\n",
            "Epoch 4/20\n",
            "7982/7982 [==============================] - 2s 219us/step - loss: 1.1435 - acc: 0.7273 - val_loss: 1.3211 - val_acc: 0.6960\n",
            "Epoch 5/20\n",
            "7982/7982 [==============================] - 2s 219us/step - loss: 1.0124 - acc: 0.7457 - val_loss: 1.2701 - val_acc: 0.7030\n",
            "Epoch 6/20\n",
            "7982/7982 [==============================] - 2s 219us/step - loss: 0.9115 - acc: 0.7583 - val_loss: 1.2755 - val_acc: 0.7110\n",
            "Epoch 7/20\n",
            "7982/7982 [==============================] - 2s 217us/step - loss: 0.8323 - acc: 0.7744 - val_loss: 1.2582 - val_acc: 0.7120\n",
            "Epoch 8/20\n",
            "7982/7982 [==============================] - 2s 221us/step - loss: 0.7708 - acc: 0.7897 - val_loss: 1.2637 - val_acc: 0.7140\n",
            "Epoch 9/20\n",
            "7982/7982 [==============================] - 2s 223us/step - loss: 0.7138 - acc: 0.8017 - val_loss: 1.2844 - val_acc: 0.7100\n",
            "Epoch 10/20\n",
            "7982/7982 [==============================] - 2s 224us/step - loss: 0.6631 - acc: 0.8120 - val_loss: 1.3255 - val_acc: 0.7070\n",
            "Epoch 11/20\n",
            "7982/7982 [==============================] - 2s 223us/step - loss: 0.6188 - acc: 0.8206 - val_loss: 1.3512 - val_acc: 0.7150\n",
            "Epoch 12/20\n",
            "7982/7982 [==============================] - 2s 224us/step - loss: 0.5806 - acc: 0.8349 - val_loss: 1.3824 - val_acc: 0.7120\n",
            "Epoch 13/20\n",
            "7982/7982 [==============================] - 2s 220us/step - loss: 0.5421 - acc: 0.8454 - val_loss: 1.4477 - val_acc: 0.7130\n",
            "Epoch 14/20\n",
            "7982/7982 [==============================] - 2s 216us/step - loss: 0.5098 - acc: 0.8553 - val_loss: 1.4662 - val_acc: 0.7130\n",
            "Epoch 15/20\n",
            "7982/7982 [==============================] - 2s 217us/step - loss: 0.4815 - acc: 0.8676 - val_loss: 1.5121 - val_acc: 0.7180\n",
            "Epoch 16/20\n",
            "7982/7982 [==============================] - 2s 220us/step - loss: 0.4514 - acc: 0.8796 - val_loss: 1.5407 - val_acc: 0.7090\n",
            "Epoch 17/20\n",
            "7982/7982 [==============================] - 2s 216us/step - loss: 0.4271 - acc: 0.8824 - val_loss: 1.5859 - val_acc: 0.7160\n",
            "Epoch 18/20\n",
            "7982/7982 [==============================] - 2s 218us/step - loss: 0.4062 - acc: 0.8904 - val_loss: 1.6252 - val_acc: 0.7100\n",
            "Epoch 19/20\n",
            "7982/7982 [==============================] - 2s 218us/step - loss: 0.3850 - acc: 0.8948 - val_loss: 1.6577 - val_acc: 0.7070\n",
            "Epoch 20/20\n",
            "7982/7982 [==============================] - 2s 218us/step - loss: 0.3681 - acc: 0.8965 - val_loss: 1.7463 - val_acc: 0.7080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb92fb62fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "EEzkV9SdFyy8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "검증 정확도의 최고 값은 약 71%로 8% 정도 감소되었습니다. 이런 손실의 대부분 원인은 많은 정보(46개 클래스의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문입니다. 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했습니다."
      ]
    },
    {
      "metadata": {
        "id": "OwCElJF3Fyy9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 추가 실험\n",
        "\n",
        "* 더 크거나 작은 층을 사용해 보세요: 32개 유닛, 128개 유닛 등\n",
        "* 여기에서 두 개의 은닉층을 사용했습니다. 한 개의 은닉층이나 세 개의 은닉층을 사용해 보세요."
      ]
    },
    {
      "metadata": {
        "id": "TAD09Gb3Fyy9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 정리\n",
        "\n",
        "다음은 이 예제에서 배운 것들입니다.\n",
        "\n",
        "* N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 `Dense` 층의 크기는 N이어야 합니다.\n",
        "* 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 `softmax` 활성화 함수를 사용해야 합니다.\n",
        "* 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 합니다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화합니다.\n",
        "* 다중 분류에서 레이블을 다루는 두 가지 방법이 있습니다.\n",
        "    * 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 `categorical_crossentropy` 손실 함수를 사용합니다.\n",
        "    * 레이블을 정수로 인코딩하고 `sparse_categorical_crossentropy` 손실 함수를 사용합니다.\n",
        "* 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 합니다."
      ]
    }
  ]
}