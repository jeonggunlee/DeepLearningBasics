{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-classifying-movie-reviews.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeonggunlee/OpenSourceKeras/blob/master/04_classifying_movie_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fxPd_GitEP9E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###한림대학교 소프트웨어 융합 대학 특강\n",
        "\n",
        "##누구나 즐기는 딥러닝: 오픈소스 Keras를 활용하여!!!\n",
        "\n",
        "이정근 교수\n",
        "\n",
        "빅데이터전공주임/오픈소스소프트웨어센터장 소프트웨어융합대학\n",
        "\n",
        "jeonggun.lee@hallym.ac.kr 2019년 5월\n",
        "\n",
        "\n",
        "---\n",
        "## IMDB 리뷰 감성 분류하기\n",
        "\n",
        "imdb의 데이터 로딩 화일이 이전 버전의 numpy를 활용하기 때문에, 이전 numpy 버전 (1.16.2)을 새롭게 설치함\n",
        "\n",
        "이를 위하여 다음 명령어를 수행\n",
        "\n",
        "**!pip install numpy==1.16.2**\n"
      ]
    },
    {
      "metadata": {
        "id": "QQf9Il94EPrm",
        "colab_type": "code",
        "outputId": "0e28ce0b-0176-47a5-9875-d6358ddfb15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.16.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.6/dist-packages (1.16.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0h4XpDobECSZ",
        "colab_type": "code",
        "outputId": "582de3f9-299e-4d24-d04d-0c332f338481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "THe9NBvLEhIk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 이하 자료는 모두 다음 사이트의 내용에서 가져온 자료입니다.\n",
        "\n",
        "https://github.com/rickiepark/deep-learning-with-python-notebooks\n",
        "\n",
        "원작자: François Chollet, https://github.com/fchollet\n",
        "\n",
        "한글화: Haesun Park (rickiepark) https://github.com/rickiepark\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9BFFhbm_ECSh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 영화 리뷰 분류: 이진 분류 예제\n",
        "\n",
        "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/케라스-창시자에게-배우는-딥러닝/) 책의 3장 4절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다. 이 노트북의 설명은 케라스 버전 2.2.2에 맞추어져 있습니다. 케라스 최신 버전이 릴리스되면 노트북을 다시 테스트하기 때문에 설명과 코드의 결과가 조금 다를 수 있습니다.\n",
        "\n",
        "----\n",
        "\n",
        "2종 분류 또는 이진 분류는 아마도 가장 널리 적용된 머신 러닝 문제일 것입니다. 이 예제에서 리뷰 텍스트를 기반으로 영화 리뷰를 긍정과 부정로 분류하는 법을 배우겠습니다."
      ]
    },
    {
      "metadata": {
        "id": "xcXwwGXnECSi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## IMDB 데이터셋\n",
        "\n",
        "인터넷 영화 데이터베이스로부터 가져온 양극단의 리뷰 50,000개로 이루어진 IMDB 데이터셋을 사용하겠습니다. 이 데이터셋은 훈련 데이터 25,000개와 테스트 데이터 25,000개로 나뉘어 있고 각각 50%는 부정, 50%는 긍정 리뷰로 구성되어 있습니다.\n",
        "\n",
        "왜 훈련 데이터와 테스트 데이터를 나눌까요? 같은 데이터에서 머신 러닝 모델을 훈련하고 테스트해서는 절대 안 되기 때문입니다! 모델이 훈련 데이터에서 잘 작동한다는 것이 처음 만난 데이터에서도 잘 동작한다는 것을 보장하지 않습니다. 중요한 것은 새로운 데이터에 대한 모델의 성능입니다(사실 훈련 데이터의 레이블은 이미 알고 있기 때문에 이를 예측하는 모델은 필요하지 않습니다). 예를 들어 모델이 훈련 샘플과 타깃 사이의 매핑을 모두 외워버릴 수 있습니다. 이런 모델은 처음 만나는 데이터에서 타깃을 예측하는 작업에는 쓸모가 없습니다. 다음 장에서 이에 대해 더 자세히 살펴보겠습니다.\n",
        "\n",
        "MNIST 데이터셋처럼 IMDB 데이터셋도 케라스에 포함되어 있습니다. 이 데이터는 전처리되어 있어 각 리뷰(단어 시퀀스)가 숫자 시퀀스로 변환되어 있습니다. 여기서 각 숫자는 사전에 있는 고유한 단어를 나타냅니다.\n",
        "\n",
        "다음 코드는 데이터셋을 로드합니다(처음 실행하면 17MB 정도의 데이터가 컴퓨터에 다운로드됩니다):"
      ]
    },
    {
      "metadata": {
        "id": "1QrzWZ2_ECSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eesTEuVZECSl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "매개변수 `num_words=10000`은 훈련 데이터에서 가장 자주 나타나는 단어 10,000개만 사용하겠다는 의미입니다. 드물게 나타나는 단어는 무시하겠습니다. 이렇게 하면 적절한 크기의 벡터 데이터를 얻을 수 있습니다.\n",
        "\n",
        "변수 `train_data`와 `test_data`는 리뷰의 목록입니다. 각 리뷰는 단어 인덱스의 리스트입니다(단어 시퀀스가 인코딩된 것입니다). `train_labels`와 `test_labels`는 부정을 나타내는 0과 긍정을 나타내는 1의 리스트입니다:"
      ]
    },
    {
      "metadata": {
        "id": "OGHQjs11ECSn",
        "colab_type": "code",
        "outputId": "3da4ff40-ce1f-4f5f-a9bc-a13a0ce80f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3941
        }
      },
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "PXy3U4DjECSr",
        "colab_type": "code",
        "outputId": "d243bb39-506f-462b-ff6f-c22423fb6149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "escBRmzXECSv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "가장 자주 등장하는 단어 10,000개로 제한했기 때문에 단어 인덱스는 10,000을 넘지 않습니다:"
      ]
    },
    {
      "metadata": {
        "id": "wZpZZUGiECSv",
        "colab_type": "code",
        "outputId": "fccfde0c-0f41-444c-9d8c-0a4f6c556f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "f-lPLyx4ECSz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "재미 삼아 이 리뷰 데이터 하나를 원래 영어 단어로 어떻게 바꾸는지 보겠습니다:"
      ]
    },
    {
      "metadata": {
        "id": "-icY3WyDECS0",
        "colab_type": "code",
        "outputId": "038061ea-79a9-49ea-b3b9-73f40b057921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "# word_index는 단어와 정수 인덱스를 매핑한 딕셔너리입니다\n",
        "word_index = imdb.get_word_index()\n",
        "# 정수 인덱스와 단어를 매핑하도록 뒤집습니다\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# 리뷰를 디코딩합니다. \n",
        "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FeRrS0gOECS2",
        "colab_type": "code",
        "outputId": "ff664d8b-66b2-45fd-9f5e-800f912d88eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "decoded_review"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "hOu9z0UtECS6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비\n",
        "\n",
        "신경망에 숫자 리스트를 주입할 수는 없습니다. 리스트를 텐서로 바꾸는 두 가지 방법이 있습니다:\n",
        "\n",
        "* 같은 길이가 되도록 리스트에 패딩을 추가하고 `(samples, sequence_length)` 크기의 정수 텐서로 변환합니다. 그다음 이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용합니다(`Embedding` 층을 말하며 나중에 자세히 다루겠습니다).\n",
        "* 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환합니다. 예를 들면 시퀀스 `[3, 5]`를 인덱스 3과 5의 위치는 1이고 그 외는 모두 0인 10,000차원의 벡터로 각각 변환합니다. 그다음 부동 소수 벡터 데이터를 다룰 수 있는 `Dense` 층을 신경망의 첫 번째 층으로 사용합니다.\n",
        "\n",
        "여기서는 두 번째 방식을 사용하고 이해를 돕기 위해 직접 데이터를 원-핫 벡터로 만들겠습니다:"
      ]
    },
    {
      "metadata": {
        "id": "1uX4svmhECS7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
        "    return results\n",
        "\n",
        "# 훈련 데이터를 벡터로 변환합니다\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 테스트 데이터를 벡터로 변환합니다\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RRpscTxhECS9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이제 샘플은 다음과 같이 나타납니다:"
      ]
    },
    {
      "metadata": {
        "id": "NqQBT6A3ECS-",
        "colab_type": "code",
        "outputId": "f0fd79b4-0307-4204-883d-be83002f70a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "x_train[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "sLG3Y7rxECTB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "레이블은 쉽게 벡터로 바꿀 수 있습니다:"
      ]
    },
    {
      "metadata": {
        "id": "8O_JlZGPECTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 레이블을 벡터로 바꿉니다\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "43kK_YsPECTF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이제 신경망에 주입할 데이터가 준비되었습니다."
      ]
    },
    {
      "metadata": {
        "id": "Wp7KsWgnECTG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 신경망 모델 만들기\n",
        "\n",
        "입력 데이터가 벡터이고 레이블은 스칼라(1 또는 0)입니다. 아마 앞으로 볼 수 있는 문제 중에서 가장 간단할 것입니다. 이런 문제에 잘 작동하는 네트워크 종류는 `relu` 활성화 함수를 사용한 완전 연결 층(즉, `Dense(16, activation='relu')`)을 그냥 쌓은 것입니다.\n",
        "\n",
        "`Dense` 층에 전달한 매개변수(16)는 은닉 유닛의 개수입니다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 됩니다. 2장에서 `relu` 활성화 함수를 사용한 `Dense` 층을 다음과 같은 텐서 연산을 연결하여 구현하였습니다:\n",
        "\n",
        "`output = relu(dot(W, input) + b)`\n",
        "\n",
        "16개의 은닉 유닛이 있다는 것은 가중치 행렬 `W`의 크기가 `(input_dimension, 16)`이라는 뜻입니다. 입력 데이터와 `W`를 점곱하면 입력 데이터가 16 차원으로 표현된 공간으로 투영됩니다(그리고 편향 벡터 `b`를 더하고 `relu` 연산을 적용합니다). 표현 공간의 차원을 '신경망이 내재된 표현을 학습할 때 가질 수 있는 자유도'로 이해할 수 있습니다. 은닉 유닛을 늘리면 (표현 공간을 더 고차원으로 만들면) 신경망이 더욱 복잡한 표현을 학습할 수 있지만 계산 비용이 커지고 원치 않은 패턴을 학습할 수도 있습니다(훈련 데이터에서는 성능이 향상되지만 테스트 데이터에서는 그렇지 않은 패턴입니다).\n",
        "\n",
        "`Dense` 층을 쌓을 때 두 가진 중요한 구조상의 결정이 필요합니다:\n",
        "\n",
        "* 얼마나 많은 층을 사용할 것인가\n",
        "* 각 층에 얼마나 많은 은닉 유닛을 둘 것인가\n",
        "\n",
        "4장에서 이런 결정을 하는 데 도움이 되는 일반적인 원리를 배우겠습니다. 당분간은 저를 믿고 선택한 다음 구조를 따라 주세요.\n",
        "\n",
        "* 16개의 은닉 유닛을 가진 두 개의 은닉층\n",
        "* 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 세 번째 층\n",
        "\n",
        "중간에 있는 은닉층은 활성화 함수로 `relu`를 사용하고 마지막 층은 확률(0과 1 사이의 점수로, 어떤 샘플이 타깃 '1'일 가능성이 높다는 것은 그 리뷰가 긍정일 가능성이 높다는 것을 의미합니다)을 출력하기 위해 시그모이드 활성화 함수를 사용합니다. `relu`는 음수를 0으로 만드는 함수입니다. 시그모이드는 임의의 값을 [0, 1] 사이로 압축하므로 출력 값을 확률처럼 해석할 수 있습니다."
      ]
    },
    {
      "metadata": {
        "id": "ZfyOYeGaECTH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "다음이 이 신경망의 모습입니다:\n",
        "\n",
        "![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"
      ]
    },
    {
      "metadata": {
        "id": "wApCFWgaECTI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "다음은 이 신경망의 케라스 구현입니다. 이전에 보았던 MNIST 예제와 비슷합니다:"
      ]
    },
    {
      "metadata": {
        "id": "PYdwr5R6ECTJ",
        "colab_type": "code",
        "outputId": "3e55726f-abdc-43ca-84bf-6f62cdb01ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eqXMbF7nECTL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "마지막으로 손실 함수와 옵티마이저를 선택해야 합니다. 이진 분류 문제이고 신경망의 출력이 확률이기 때문에(네트워크의 끝에 시그모이드 활성화 함수를 사용한 하나의 유닛으로 된 층을 놓았습니다), `binary_crossentropy` 손실이 적합합니다. 이 함수가 유일한 선택은 아니고 예를 들어 `mean_squared_error`를 사용할 수도 있습니다. 확률을 출력하는 모델을 사용할 때는 크로스엔트로피가 최선의 선택입니다. 크로스엔트로피는 정보 이론 분야에서 온 개념으로 확률 분포 간의 차이를 측정합니다. 여기에서는 원본 분포와 예측 분포 사이를 측정합니다.\n",
        "\n",
        "다음은 `rmsprop` 옵티마이저와 `binary_crossentropy` 손실 함수로 모델을 설정하는 단계입니다. 훈련하는 동안 정확도를 사용해 모니터링하겠습니다."
      ]
    },
    {
      "metadata": {
        "id": "ejzUuLe5ECTN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5XZKz8zaECTQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "케라스에 `rmsprop`, `binary_crossentropy`, `accuracy`가 포함되어 있기 때문에 옵티마이저, 손실 함수, 측정 지표를 문자열로 지정하는 것이 가능합니다. 이따금 옵티마이저의 매개변수를 바꾸거나 자신만의 손실 함수, 측정 함수를 전달해야 할 경우가 있습니다. 전자의 경우에는 옵티마이저 파이썬 클래스를 사용해 객체를 직접 만들어 `optimizer` 매개변수에 전달하면 됩니다:"
      ]
    },
    {
      "metadata": {
        "id": "RXTPm7WAECTR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R0CdcHTKECTW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "후자의 경우는 `loss`와 `metrics` 매개변수에 함수 객체를 전달하면 됩니다:"
      ]
    },
    {
      "metadata": {
        "id": "Zc3Fm6giECTX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=[metrics.binary_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BIB5VW9DECTa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OODVEBG2ECTe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 훈련 검증\n",
        "\n",
        "훈련하는 동안 처음 본 데이터에 대한 모델의 정확도를 측정하기 위해서는 원본 훈련 데이터에서 10,000의 샘플을 떼어서 검증 세트를 만들어야 합니다:"
      ]
    },
    {
      "metadata": {
        "id": "4aA5gRkpECTf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Cvh88iY3ECTh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이제 모델을 512개 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련시킵니다(`x_train`과 `y_train` 텐서에 있는 모든 샘플에 대해 20번 반복합니다). 동시에 따로 떼어 놓은 10,000개의 샘플에서 손실과 정확도를 측정할 것입니다. 이렇게 하려면 `validation_data` 매개변수에 검증 데이터를 전달해야 합니다:"
      ]
    },
    {
      "metadata": {
        "id": "MYV7YTZPECTi",
        "colab_type": "code",
        "outputId": "2b66d438-59e5-47f3-d46b-6f9670125f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 2s 161us/step - loss: 0.5084 - acc: 0.7813 - val_loss: 0.3797 - val_acc: 0.8684\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 91us/step - loss: 0.3004 - acc: 0.9047 - val_loss: 0.3004 - val_acc: 0.8897\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.2179 - acc: 0.9285 - val_loss: 0.3085 - val_acc: 0.8711\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.1750 - acc: 0.9437 - val_loss: 0.2840 - val_acc: 0.8832\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 91us/step - loss: 0.1427 - acc: 0.9543 - val_loss: 0.2841 - val_acc: 0.8872\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 91us/step - loss: 0.1150 - acc: 0.9650 - val_loss: 0.3166 - val_acc: 0.8772\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0980 - acc: 0.9705 - val_loss: 0.3127 - val_acc: 0.8846\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.0807 - acc: 0.9763 - val_loss: 0.3859 - val_acc: 0.8649\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0661 - acc: 0.9821 - val_loss: 0.3635 - val_acc: 0.8782\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 91us/step - loss: 0.0561 - acc: 0.9853 - val_loss: 0.3843 - val_acc: 0.8792\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 91us/step - loss: 0.0439 - acc: 0.9893 - val_loss: 0.4153 - val_acc: 0.8779\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0381 - acc: 0.9921 - val_loss: 0.4525 - val_acc: 0.8690\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.0300 - acc: 0.9928 - val_loss: 0.4698 - val_acc: 0.8729\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.0247 - acc: 0.9945 - val_loss: 0.5022 - val_acc: 0.8726\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.0175 - acc: 0.9979 - val_loss: 0.5340 - val_acc: 0.8693\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.0149 - acc: 0.9983 - val_loss: 0.5710 - val_acc: 0.8698\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0151 - acc: 0.9971 - val_loss: 0.6024 - val_acc: 0.8697\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0075 - acc: 0.9996 - val_loss: 0.6782 - val_acc: 0.8633\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.0117 - acc: 0.9975 - val_loss: 0.6692 - val_acc: 0.8674\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.0041 - acc: 0.9999 - val_loss: 0.6940 - val_acc: 0.8658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hQLfpUezECTl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CPU를 사용해도 에포크마다 2초가 걸리지 않습니다. 전체 훈련은 20초 이상 걸립니다. 에포크가 끝날 때마다 10,000개의 검증 샘플 데이터에서 손실과 정확도를 계산하기 때문에 약간씩 지연됩니다.\n",
        "\n",
        "`model.fit()` 메서드는 `History` 객체를 반환합니다. 이 객체는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리인 `history` 속성을 가지고 있습니다. 한 번 확인해 보죠:"
      ]
    },
    {
      "metadata": {
        "id": "nyYGnGpUECTm",
        "colab_type": "code",
        "outputId": "ea530ec7-b598-4720-c597-d0a2208bf9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "4qc1dSLGECTp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 딕셔너리는 훈련과 검증하는 동안 모니터링할 측정 지표당 하나씩 모두 네 개의 항목을 담고 있습니다. 맷플롯립을 사용해 훈련과 검증 데이터에 대한 손실과 정확도를 그려 보겠습니다:"
      ]
    },
    {
      "metadata": {
        "id": "WaTZZqWpECTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OT-hbiMZECTs",
        "colab_type": "code",
        "outputId": "3ea4c098-2895-4a01-f3dd-6566148bcc75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# ‘bo’는 파란색 점을 의미합니다\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# ‘b’는 파란색 실선을 의미합니다\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "guCw2RgXECTv",
        "colab_type": "code",
        "outputId": "0af1f300-d2f5-4c95-f6c4-89d7d0c4e37d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "cell_type": "code",
      "source": [
        "plt.clf()   # 그래프를 초기화합니다\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "73CnReJvECTy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "점선은 훈련 손실과 정확도이고 실선은 검증 손실과 정확도입니다. 신경망의 무작위한 초기화 때문에 사람마다 결과거 조금 다를 수 있습니다.\n",
        "\n",
        "여기에서 볼 수 있듯이 훈련 손실이 에포크마다 감소하고 훈련 정확도는 에포크마다 증가합니다. 경사 하강법 최적화를 사용했을 때 반복마다 최소화되는 것이 손실이므로 기대했던 대로입니다. 검증 손실과 정확도는 이와 같지 않습니다. 4번째 에포크에서 그래프가 역전되는 것 같습니다. 이것이 훈련 세트에서 잘 작동하는 모델이 처음 보는 데이터에 잘 작동하지 않을 수 있다고 앞서 언급한 경고의 한 사례입니다. 정확한 용어로 말하면 과대적합되었다고 합니다. 2번째 에포크 이후부터 훈련 데이터에 과도하게 최적화되어 훈련 데이터에 특화된 표현을 학습하므로 훈련 세트 이외의 데이터에는 일반화되지 못합니다.\n",
        "\n",
        "이런 경우에 과대적합을 방지하기 위해서 3번째 에포크 이후에 훈련을 중지할 수 있습니다. 일반적으로 4장에서 보게 될 과대적합을 완화하는 다양한 종류의 기술을 사용할 수 있습니다.\n",
        "\n",
        "처음부터 다시 새로운 신경망을 4번의 에포크 동안만 훈련하고 테스트 데이터에서 평가해 보겠습니다:"
      ]
    },
    {
      "metadata": {
        "id": "bm-4SIXQECTz",
        "colab_type": "code",
        "outputId": "3449438b-f6bd-4db8-998b-10e6dc8a9f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 2s 67us/step - loss: 0.4749 - acc: 0.8217\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 1s 58us/step - loss: 0.2666 - acc: 0.9096\n",
            "Epoch 3/4\n",
            "25000/25000 [==============================] - 1s 58us/step - loss: 0.1987 - acc: 0.9292\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 1s 57us/step - loss: 0.1679 - acc: 0.9402\n",
            "25000/25000 [==============================] - 2s 80us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LKDT8j4LECT2",
        "colab_type": "code",
        "outputId": "d659a782-0edb-4a90-8fe6-d88b81feb489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "results"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3238562201786041, 0.87308]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "RFs3q6zsECT5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "아주 단순한 방식으로도 87%의 정확도를 달성했습니다. 최고 수준의 기법을 사용하면 95%에 가까운 성능을 얻을 수 있습니다."
      ]
    },
    {
      "metadata": {
        "id": "BJ7yWJ16ECT7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 훈련된 모델로 새로운 데이터에 대해 예측하기\n",
        "\n",
        "모델을 훈련시킨 후에 이를 실전 환경에서 사용하고 싶을 것입니다. `predict` 메서드를 사용해서 어떤 리뷰가 긍정일 확률을 예측할 수 있습니다:"
      ]
    },
    {
      "metadata": {
        "id": "V2ueU15lECT9",
        "colab_type": "code",
        "outputId": "4b3636a5-f2cd-4a39-cace-eaa59aee1bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13560072],\n",
              "       [0.99971175],\n",
              "       [0.27816337],\n",
              "       ...,\n",
              "       [0.07139972],\n",
              "       [0.04283798],\n",
              "       [0.4738391 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "64d7tKWoECUA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "여기에서처럼 이 모델은 어떤 샘플에 대해 확신을 가지고 있지만(0.99 또는 그 이상, 0.01 또는 그 이하) 어떤 샘플에 대해서는 확신이 부족합니다(0.6, 0.4). "
      ]
    },
    {
      "metadata": {
        "id": "yAc3atWNECUB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 추가 실험\n",
        "\n",
        "* 여기에서는 두 개의 은닉층을 사용했습니다. 한 개 또는 세 개의 은닉층을 사용하고 검증과 테스트 정확도에 어떤 영향을 미치는지 확인해 보세요.\n",
        "* 층의 은닉 유닛을 추가하거나 줄여 보세요: 32개 유닛, 64개 유닛 등\n",
        "* `binary_crossentropy` 대신에 `mse` 손실 함수를 사용해 보세요.\n",
        "* `relu` 대신에 `tanh` 활성화 함수(초창기 신경망에서 인기 있었던 함수입니다)를 사용해 보세요.\n",
        "\n",
        "다음 실험을 진행하면 여기에서 선택한 구조가 향상의 여지는 있지만 어느 정도 납득할 만한 수준이라는 것을 알게 것입니다!"
      ]
    },
    {
      "metadata": {
        "id": "Z90HlzE_ECUC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 정리\n",
        "\n",
        "다음은 이 예제에서 배운 것들입니다:\n",
        "\n",
        "* 원본 데이터를 신경망에 텐서로 주입하기 위해서는 꽤 많은 전처리가 필요합니다. 단어 시퀀스는 이진 벡터로 인코딩될 수 있고 다른 인코딩 방식도 있습니다.\n",
        "* `relu` 활성화 함수와 함께 `Dense` 층을 쌓은 네트워크는 (감성 분류를 포함하여) 여러 종류의 문제에 적용할 수 있어서 앞으로 자주 사용하게 될 것입니다.\n",
        "* (출력 클래스가 두 개인) 이진 분류 문제에서 네트워크는 하나의 유닛과 `sigmoid` 활성화 함수를 가진 `Dense` 층으로 끝나야 합니다. 이 신경망의 출력은 확률을 나타내는 0과 1 사이의 스칼라 값입니다.\n",
        "* 이진 분류 문제에서 이런 스칼라 시그모이드 출력에 대해 사용할 손실 함수는 `binary_crossentropy`입니다.\n",
        "* `rmsprop` 옵티마이저는 문제에 상관없이 일반적으로 충분히 좋은 선택입니다. 걱정할 거리가 하나 줄은 셈입니다.\n",
        "* 훈련 데이터에 대해 성능이 향상됨에 따라 신경망은 과대적합되기 시작하고 이전에 본적 없는 데이터에서는 결과가 점점 나빠지게 됩니다. 항상 훈련 세트 이외의 데이터에서 성능을 모니터링해야 합니다."
      ]
    }
  ]
}